## üìÑ Documenta√ß√£o do Prot√≥tipo de Extra√ß√£o RPI (INPI)

### 1. Ferramentas Utilizadas

O prot√≥tipo foi constru√≠do em Python e depende das seguintes bibliotecas:

* **`xml.etree.ElementTree`**: Uma biblioteca nativa do Python, usada para a an√°lise (parsing) e navega√ß√£o na estrutura do arquivo `.xml` da RPI.
* **`pandas`**: Biblioteca essencial para a estrutura√ß√£o dos dados. Foi usada para converter a lista de dados extra√≠dos em um DataFrame (tabela).
* **`openpyxl`**: Depend√™ncia utilizada pelo `pandas` para permitir a escrita de dados no formato `.xlsx` (Excel).
* **`os`**: Biblioteca nativa do Python, usada para verificar se o arquivo `.xml` de entrada existe no diret√≥rio.

### 2. L√≥gica do Programa

O script `processar_rpi.py` executa a seguinte l√≥gica:

1.  **Carregar:** O script primeiro localiza e analisa (faz o *parse*) do arquivo `.xml` de entrada (ex: `RPI_2861.xml`) usando a biblioteca `ElementTree`.
2.  **Iterar:** Ele encontra o elemento raiz (`<revista>`) e, em seguida, entra em um loop para localizar cada ocorr√™ncia da tag `<despacho>`.
3.  **Extrair:** Dentro de cada `<despacho>`, o script navega pelas tags filhas (como `<processo-patente>`, `<numero>`, `<data-deposito>` e `<titular-lista>`) para extrair os dados de interesse.
    * *Robustez:* O script verifica a exist√™ncia de elementos-chave (como `<processo-patente>`) antes de tentar extrair dados deles, evitando erros caso um despacho n√£o contenha essa estrutura.
4.  **Estruturar:** Cada conjunto de dados extra√≠dos de um despacho √© armazenado em um dicion√°rio Python. Todos os dicion√°rios s√£o agrupados em uma lista √∫nica.
5.  **Converter:** Ao final do loop, a lista completa de dicion√°rios √© carregada em um DataFrame do `pandas`, transformando os dados em um formato de tabela.
6.  **Exportar:** O DataFrame final √© exportado para dois arquivos distintos no mesmo diret√≥rio:
    * Um arquivo `.csv` (codificado em `utf-8-sig` para garantir a compatibilidade de acentos).
    * Um arquivo `.xlsx` (Excel), com a aba nomeada dinamicamente com o n√∫mero da revista.

### 3. Pr√≥ximos Passos (Expans√£o do Projeto)

Com a l√≥gica de *parsing* (extra√ß√£o) validada, o pr√≥ximo passo √© automatizar a **aquisi√ß√£o dos dados**. O plano √© desenvolver um segundo componente (um *web scraper*) que ir√°:

1.  **Navegar:** Acessar o portal de publica√ß√µes do INPI.
2.  **Rastrear:** Identificar e coletar os links de download para os arquivos `.xml` das RPIs desejadas (seja de um per√≠odo espec√≠fico ou as mais recentes).
3.  **Baixar:** Fazer o download autom√°tico desses arquivos `.xml` para uma pasta local.
4.  **Integrar:** (Opcional) Ap√≥s o download, o *scraper* pode invocar automaticamente o script de *parsing* que criamos para processar cada novo arquivo baixado, automatizando o fluxo de trabalho do in√≠cio ao fim.
